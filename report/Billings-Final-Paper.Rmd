---
title: "Infectivity of human norovirus in live challenge trials: a systematic review and meta-analysis"
author:
  - name: W. Zane Billings
    institute: one
  - name: Anne Marie Dye
    institute: two
  - name: Andreas Handel
    institute: one
institute:
  - one: Department of Epidemiology and Biostatistics, College of Public Health, University of Georgia
  - two: Department of Environmental Health, College of Public Health, University of Georgia
date: "2021-12-13"
output:
  bookdown::word_document2: 
    toc: false
    pandoc_args:
      - '--lua-filter=scholarly-metadata.lua'
      - '--lua-filter=author-info-blocks.lua'
    number_sections: FALSE
    fig_cap: TRUE
bibliography:
  - "http://127.0.0.1:23119/better-bibtex/export/collection?/1/E6YNTUCZ.biblatex"
  - "r-refs.bib"
csl: jama.csl
abstract: |
  Human norovirus is the most common cause of acute gastroenteritis and food-borne illness in the United States. Norovirus is spread primarily by the fecal-oral route and is highly transmissible, but norovirus outbreaks are often self-limiting. The wide variety of potential routes of exposure make estimates of transmissibility from outbreak data somewhat unreliable. In contrast, human challenge studies involve a controlled inoculation, where experimental settings and route of transmission can be controlled, among other factors. In this way, norovirus challenge studies fill a unique niche in the literature and provide rich data for studying norovirus infection. However, there is no consensus on how many norovirus challenge studies have been conducted in the past, or what data were collected. We conducted a systematic review of the literature in order to find all studies which report using norovirus challenge data, and from these studies, we abstract data to obtain unique challenge cohort data. From unique cohorts, we conduct a meta-analysis of the proportion of individuals infected during each study, including subgroup analyses by study risk of bias, inoculum genogroup, and FUT2 participant genotype control. We find a high degree of heterogeneity among studies, which is somewhat explained by outliers, and not explained by any abstracted covariates. Our results suggest that either proportion of infected individuals in a norovirus challenge study is naturally heterogeneous, or is influenced primarily by unmeasured covariates. As potential infection rates may be dependent on several characteristics of research protocols, norovirus inoculum, research staff, and study participants, our results seem reasonable.
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

# Loading required packages
## For reporting
library(rmarkdown)
library(bookdown)
library(knitr)

## For tables
library(flextable)

## For figures
library(PRISMA2020)
library(robvis)

## For analysis
library(meta)
library(metafor)
library(dmetar)

## Other
library(here)
library(janitor)
library(magick)
library(rsvg)
library(DiagrammeRsvg)
library(dplyr)

# Write r-refs bibliography
knitr::write_bib(file = "r-refs.bib")
```

Word count:

Number of tables:

Number of figures:

\newpage

# Introduction

Human norovirus (NoV) is a small, round-structured, unenveloped, positive-sense single-strand RNA virus with a linear, unsegmented genome, belonging to the caliciviridae family [CITE THIS]. NoV was first isolated in YEAR (CITE THIS), and has been a constant annoyance since then. In the United Status, NoV is responsible for over 50\% of foodborne illnesses, and is the most common single cause of gastroenteritis (CITE THIS). Norovirus is spread via the fecal-oral and vomit oral routes (CITE THIS), and a combination of low infectious viral load, potential for aerosolization, and environmental persistence can make norovirus highly transmissible. 

Most norovirus outbreaks are self-limiting, and transmission to an individual can be highly variable due to the number of possible routes of exposure. Study of norovirus transmission is further complicated by differences in virulence between genotypes (CITE THIS) and heterogeneous host immune and genetic profiles (CITE THIS). Based on these factors, estimates of transmissibility and infectivity can often be variable by outbreak. However, human challenge studies offer a controlled setting where viral properties of NoV can be examined. During a challenege study, healthy individuals are administered live norovirus after which subjects are closely monitored for the duration of inducted illness. Such challenge studies provide the opportunity to control factors like inoculum strain, inoculum dose, and participant histo-blood group. Recall bias is also less likely to influence the result of challenge studies. Thus, using challenge studies to explore norovirus infectivity is less prone to bias than challenge studies, even if the results are not always generalizable to natural outbreaks.



# Methods

We conducted a systematic review of papers using data from norovirus challenge studies, and from the included reports, we identified unique studies. Then, we abstracted data on the proportion of infected individuals from each study, and conducted a meta-analysis of these data.

## Literature search

We searched two databases to find literature:

* PubMed [(https://www.ncbi.nlm.nih.gov/pubmed/)](https://www.ncbi.nlm.nih.gov/pubmed/) and
* Web of Science [(https://www.webofscience.com/)](https://www.webofscience.com/).

The search terms, included in Table \@ref(tab:SearchTerms), contained terms for norovirus, terms related to human studies, and terms related to the challenge (or volunteer) study design. The databases were searched on September ##, 2021, with no filter for date used during the search.

```{r SearchTerms}
STtable <- data.frame(
  database = c("PubMed", "WoS"),
  search = c(
    paste(
      '("norovirus" [MeSH Major Topic]) AND',
      '("norovirus" OR "Norwalk virus" OR "snow mountain virus" OR',
      '\t "Norwalk agent" OR "nonbacterial gastroenteritis" OR',
      '\t "viral gastroenteritis" [Title/Abstract]) AND',
      '(human OR challenge OR experimental OR infect* OR volunteer OR',
      '\t vaccin* OR adult OR clinical OR randomized OR',
      '\t individual [Title/Abstract]) NOT',
      '("mouse" or "murine" or "mice" [Title])',
      sep = "\n"
    ),
    paste(
      '(TS=("norovirus" OR "Norwalk virus" OR "snow mountain virus" OR',
      '\t "Norwalk agent" OR "nonbacterial gastroenteritis" OR',
      '\t "viral gastroenteritis")) AND',
      '(TS=(human OR man OR adult OR volunteer)) AND',
      '(TS=(volunteer OR challenge OR experimental OR infect* OR vaccin* OR',
      '\t inoculum))',
      sep = "\n"
    )
  )
) |>
  flextable::flextable() |>
  flextable::set_header_labels(search = "search strategy") |>
  flextable::theme_booktabs(bold_header = TRUE) |>
  flextable::align(j = 1, align = "right", part = "all") |>
  flextable::align(j = 2, align = "left", part = "all") |>
  flextable::set_caption("Search strings for the two databases searched.") |>
  flextable::fontsize(size = 8, part = "all") |>
  flextable::autofit() |>
  flextable::set_table_properties(layout = "autofit")

STtable
```

Reports were selected for inclusion if they referenced a human norovirus challenge study with controlled inoculation of participants. No other inclusion criteria (location, date, study design, etc.) were used. Reports were excluded from the review if they were not primary research articles (i.e. reviews or letters to the editor), not written in English, or not available to the authors. Two reviewers (WZB and AMD) independently reviewed titles and abstracts, with disagreements being resolved by a third reviewer (AH). The reviewers repeated the process for the full-text review.

From the included reports, the reviewers identified unique studies by examining citations for data sources. We created a directed acyclic graph (DAG) based on citations in reference sections of papers--in this format, the end notes of the DAG are studies with original populations. Only reports which appeared to discuss original data collection and did not cite their data as coming from a previous report were considered to be unique studies.

## Data abstraction

From each study (only reports which included original data collection), one author (WZB) abstracted the following information:

1. Reference information including name of the first author and the year of publication;
2. Study design for the challenge portion of the study (either case series or randomized trial);
3. Demographic information reported for each study including age range, percentage of male participants, percentage of white participants, and location of the study site;
4. Whether the study controlled for participant FUT2 genotype;
5. Any other eligibility criteria for study enrollment;
6. Inoculum dose and genotype;
7. Criteria for reporting infection and illness; and
8. For each combination of FUT2 status, dose, and other study sub-samples (e.g. vaccine vs. placebo in vaccine trials), the number of participants challenged, number of participants with confirmed infection, and the number of participants with confirmed illness.

Reported inoculum strains were standardized to modern nomenclature where possible, criteria for infection and illness were standardized, and inoculum dose was converted to genome equivalent copies (1 RT-PCR unit = 400 genome equivalent copies) [@atmar2014].

## Study quality assessment

Study quality was assessed using a modification of the JBI critical appraisal tool for case series studies [@munn2020]. All included studies were evaluated on this scale by one author (WZB). Studies were assessed on seven domains: clear inclusion criteria, reliability of infection assessment, validity of infection assessment, whether all participants were drawn from the same cohort, complete reporting of relevant demographic information, complete reporting of relevant clinical information, and reporting of study site information. The full rubric for assessing studies is included in the appendix.

## Statistical methods

We fit an overall meta-analysis model for the proportion of infected individuals (proportion infected) by pooling together all subgroups reported within each study. We used a generalized linear mixed-effected modeling approach with logit-transformed proportions (log-odds) as the outcome [@stijnen2010; @harrer2021]. The method of maximum likelihood was used to estimate $\tau^2$ (between-study heterogeneity). Confidence intervals for pooled effects were calculated using the Knapp-Hartung adjustment [@knapp2003; @sidik2002], which is typically sensible [@harrer2021; @inthout2014; @langan2019]. The GLMM method with log-odds as the outcome has been previously recommended in the literature for the meta-analysis of proportions [@schwarzer2019]. When using a GLMM approach, no weights are estimated for each study, and $\tau^2$ (the estimate of between-study heterogeneity) can only be estimated through the method of maximum likehood, and a confidence interval for $\tau^2$ cannot be obtained [@harrer2021].

*A priori* subgroup analyses were conducted to examine the effect of study risk of bias (high risk of bias vs. other studies), norovirus genogroup (GI, GII, or unknown), and whether FUT2 was controlled for in the study. For subgroup analyses, we use the so-called "fixed-effects (plural)" model for between-subgroup differences [@harrer2021; @borenstein2009; @borenstein2013]. Estimated between-study heterogeneity ($\tau^2$) was assumed to be different for all subgroups, and models within-subgroups were fit used the random-effects GLMM method as previously described. Differences between subgroups were assessed visually and using differences in $I^2$ rather than by conducting any formal statistical test. The effect of year of publication was examined visually, rather than by conducting any additional analyses.

Influence of individual studies on the overall result was analyzed *post-hoc* using three methods. First, we used a simple method which classifies studies as outliers if the estimate confidence interval for the individual study does not overlap with the confidence interval for the pooled estimate [@harrer2021]. Second, we used a leave-one-out approach and manually identified outliers using a Baujat plot [@baujat2002] and diagnostics [@viechtbauer2010]. Third, we used the GOSH (Graphical display Of Study Heterogeneity) method, wherein we fit 1,000,000 models with random subsets of studies included. Then, we plotted the estimated heterogeneity vs. the estimated effect size of all random subset analyses [@olkin2012]. From the GOSH results, we applied three unsupervised clustering algorithms: $k$-means [@hartigan1979], DBSCAN [@schubert2017], and Gaussian mixture modeling [@fraley2002]. Study over-representation within clusters is used to determine which studies have an undue effect on heterogeneity [@harrer2021]. Overall, outliers were detected by consensus--if any two of the three methods flagged a particular study, that study was designated as an outlier.

<!--To assess the effect of inoculum dose on proportion infected, we performed a meta-regression using proportion infected as the response and inoculum dose as the explanatory variable. The method of maximum likelihood was used to estimate $\tau^2$, as previously described. The $R^2_*$ metric estimates the reduction in heterogeneity variance from the regression model, compared to the overall random-effects model, and was therefore used as a metric for goodness-of-fit. The slope coefficient was tested for significance using the Knapp-Hartung adjustment for the Wald-type test [@harrer2021].-->

Finally, since we have more than 10 studies [@sterne2011], we assessed publication bias graphically using a contour-enhanced funnel plot [@peters2008] and numerically using Peters' test [@peters2008]. Peters' test accounts for dependence between the effect size and standard error for effect sizes based on binary outcome data. The common method, Egger's test [@egger1997], does not, so Peters' test has a lower false positive rate in comparison [@harrer2021; @peters2008].

## Software

Reference management was conducted using both EndNote [@endnote] for deduplication and searching for missing reference fields, and Zotero [@zotero] for archival purposes. Data abstraction and review of reports was conducted using Microsoft Excel 365 (Microsoft Corporation, Santa Rosa, CA, USA) and Google Sheets (Google, Mountain View, CA, USA).

All analyses were conducted using R version 4.1.1 [@R-base]. The packages `meta` [@R-meta; @meta2019], `metafor` [@R-metafor; @metafor2010], and `dmetar` [@R-dmetar; @harrer2021] were used for meta-analysis. Figures were generated using the analysis packages, `robvis` [@R-robvis], and `PRISMA2020` [@R-PRISMA2020; @PRISMA20202021; @haddaway2021]. Tables were generated using the package `flextable` [@R-flextable]. This report was generated using R Markdown with the packages `rmarkdown` [@R-rmarkdown; @rmarkdown2018; @rmarkdown2020], `knitr` [@R-knitr; @knitr2014; @knitr2015], and `bookdown` [@R-bookdown; @bookdown2016]. Several additional packages were used for data cleaning and wrangling, and for miscellaneous tasks [@R-here; @R-janitor; @R-magick; @R-rsvg; @R-DiagrammeRsvg; @R-dplyr]. A complete printout of the R session information can be found in the Appendix.

# Results

## Identification of studies

Overall, 5301 non-duplicate records were obtained from searching PubMed and Web of Science. After reviewing the titles and abstracts of records, 98 reports were sought for retrieval. Of those, two reports could not be obtained, and so 96 reports were retrieved for full-text review. After applying the eligibility criteria, we selected 65 reports for inclusion in the study. The PRISMA diagram for study inclusion is shown in Figure \@ref(fig:PRISMA).

```{r PRISMA, fig.cap = "PRISMA 2020 flow diagram showing how many records and reports were identified at each stage of the review process."}
knitr::include_graphics(here::here("figures", "PRISMA-diagram.png"))
```

From the list of included reports, we determined the reports which reflect original data collection by examining the methods reported in the paper. A DAG showing citations pointing to original data sources is shown in Figure \@ref(fig:DAG). In total, 20 papers reflecting original sources of data were selected for inclusion in synthesis results [@agus1973; @atmar2011; @atmar2008; @atmar2014; @bernstein2015; @dolin1971; @frenck2012; @gordon1956; @graham1994; @keswick1985; @leon2011; @lindesmith2005; @lindesmith2003; @madore1990; @mateo2020; @okhuysen1995; @parker1994; @seitz2011; @teunis2008; @treanor1988]. Of the 65 reports included [@agus1973; @ajami2012; @atmar2008; @atmar2011; @atmar2014; @atmar2015; @ball1999; @bernstein2015; @brinker1998; @brinker1999; @czako2012; @czako2015; @dai2015; @dolin1971; @erdman1989; @erdman1989a; @frenck2012; @gary1987; @gordon1956; @graham1994; @gray1994; @griffin2015; @grohmann1981; @harrington2002; @hesse2016; @hutson2002; @hutson2005; @jiang1992; @jiang1995; @kavanagh2011; @keswick1985; @kirby2014; @kirby2016; @kirby2020; @leon2011; @lindesmith2003; @lindesmith2005; @lindesmith2010; @lindesmith2015; @lindesmith2019; @liu2013; @liu2021; @lobue2006; @madore1990; @mateo2020; @messner2014; @moe2004; @newman2015; @newman2015a; @newman2016; @okhuysen1995; @parker1993; @parker1994; @patin2020; @ramani2015; @ramani2017; @reeck2010; @seitz2011; @swanstrom2014; @teunis2008; @teunis2020; @treanor1988; @treanor1993; @williams2019; @wyatt1974], 7 appeared to reflect original sources of data, but either did not provide the results necessary for synthesis, or provided the results in a format that was not usable for data extraction [@grohmann1981; @harrington2002; @lindesmith2010; @lindesmith2019; @liu2013; @moe2004; @parker1993].

```{r DAG, fig.cap = "DAG showing citations which indicated the terminal study as the source of the data. The end notes colored in green are the reports which were identified as original data collection studies."}
knitr::include_graphics(here::here("figures", "papers-dag.png"))
```

## Study characteristics

The abstracted study characteristics for the 20 included papers are shown in Table \@ref(tab:StudyCharacteristics). The earliest study was conducted in 1956, and the most recent study was conducted in 2020, with 15/20 of the studies conducted in 1990 or later, and 11/20 of the studies conducted in 2000 or later. All studies were conducted in the United States, in at least 8 different states. Most studies (15/20) reported information on the age range of participants, and all studies only included adults, as expected for challenge studies. The three oldest studies only included male subjects, but later studies tended to include an equal balance of male and female participants, where reported. Racial diversity in cohorts was reported in less than half of the included studies, and varied significantly by study. Half of the included studies (10/20) either reported results stratified by FUT2 (secretor) genotype or only recruited participants with FUT2+ genotype. Three studies only included participants with A or O blood types. Only one study (Frenck 2012) reported low pre-challenge titer as an eligibility criterion for subject recruitment. Note that the two oldest studies recruited participants at least partially from incarcerated populations--while the studies claim that the subjects are volunteers, neither study reports methods for preventing coercive recruiting, nor mentions how incarcerated subjects were compensated. These studies likely fail to meet modern ethical guidelines, but we chose to include the data in our synthesis in the hopes that some good can come out of past scientific misconduct.

```{r StudyCharacteristics}
scdat <- read.csv(here::here("data", "study-characteristics.csv"), nrows = 20)
scdat %>%
  dplyr::select(-EndNote.record.., -Other.Info, -Study.type) %>%
  dplyr::arrange(Year.published) %>%
  dplyr::mutate(
    Age = gsub(", ", " - ", Age),
    Study = paste(First.author, Year.published),
    .keep = "unused"
  ) %>%
  dplyr::select(Study, N, e, everything()) %>%
  janitor::clean_names(sep_out = " ") %>%
  flextable::flextable() |>
  flextable::set_header_labels(
    male = "% male",
    white = "% white",
    `fut2 control` = "FUT2",
    `ro b` = "RoB"
  ) %>%
  flextable::theme_booktabs(bold_header = TRUE) %>%
  flextable::align(align = "left", part = "all") %>%
  flextable::set_caption("Abstracted demographic information and other study characteristics for the 20 unique original data collection studies which were identified.") %>%
  flextable::footnote(
    i = 1, j = c(2,3,9), part = "header",
    value = flextable::as_paragraph(c("Sample size", "Number of events",
                                      "Whether subject FUT2 genotype status was measured"))
  ) %>%
  flextable::fontsize(size = 10, part = "all") %>%
  flextable::autofit() %>%
  flextable::set_table_properties(layout = "autofit")
```

The majority of the studies (11/20) were judged to be at high risk of bias. A summary plot of the risk of bias for the included studies is shown in Figure \@ref(fig:RoBSummary). The most common issue was whether the recruited participants were from the same underlying cohort (or if the study stratified results by cohort) and whether inclusion criteria were clearly reported. Note that there are no high risk of bias studies which were conducted after 2010--many older studies lacked the same standardized reporting which is now commonplace, and so have a higher risk of bias. Furthermore, older reports often tended to report the results of multiple challenge studies simultaneously, without stratifying results by cohort. Risk of bias domain assessments for each study are shown in Figure \@ref(fig:Stoplight).

```{r RoBSummary, fig.cap = "Summary risk of bias estimates for each domain across the entire set of included studies. Percentages are weighted by study size."}
knitr::include_graphics(here::here("figures", "rob-summary.png"))
```

```{r Stoplight, fig.cap = "Individual risk of bias assessments in each domain for all included studies."}
knitr::include_graphics(here::here("figures", "rob-traffic-light.png"))
```

## Meta-analysis

```{r MetaOverall, fig.cap = "Forest plot showing estimates for individual studies, along with the random-effects summary estimate."}
knitr::include_graphics(here::here("figures", "all-studies-forest.png"))
```

Estimates of the estimated proportion and 95% confidence interval for each study, along with the estimated random-effects summary estimate are shown in Figure \@ref(fig:MetaOverall). Individual point estimates for each study range from 0.36 to 1.00, with 95% confidence limits ranging from 0.22 at the lowest to 1.00 at the highest. The heterogeneity among studies is extremely high, estimated at $I^2 = 80\%$, and the 95% prediction interval indicates a low level of precision in the summary estimate. The summary estimate is unlikely to be trustworthy due to the high degree of heterogeneity present.

In order to examine the heterogeneity between studies, we examined several *a priori* subgroup analyses. The first subgroup analysis we considered was the effect of stratifying by FUT2 genogroup, shown in Figure \@ref(fig:MetaFUT). Stratifying by FUT2 control status minimally reduces the within-subgroup heterogeneity as well as the overall heterogeneity. For both subgroups (FUT2 not controlled and FUT2 status controlled for), the summary estimates and $I^2$ values are similar to the overall pooled measure, indicating little difference between subgroups. The 95% prediction interval for the overall effect is slightly smaller, as is the overall $I^2$ value, but controlling for FUT2 appears to explain only a slight fraction of heterogeneity in the outcome.

```{r MetaFUT}
knitr::include_graphics(here::here("figures", "fut2-forest.png"))
```

Next, we conducted a subgroup analysis using norovirus genogroup as the stratifying variable. The results are shown in Figure \@ref(fig:MetaGG). Interestingly, we notice that the studies which do not report the inoculum genogroup (Genogroup unknown) are quite homogeneous, $I^2 = 0\%$, although the summary estimate and prediction interval are wide. However, the more interesting comparison is between studies reporting a genogroup I inoculum and studies reporting a genogroup II inoculum. Among these two groups, stratifying by genogroup does not reduce heterogeneity at all compared to the overall analysis.

```{r MetaGG}
knitr::include_graphics(here::here("figures", "gg-forest.png"))
```

The final planned subgroup analysis we conducted was stratified by risk of bias (high risk of bias studies compared to low/medium risk of bias studies, which were pooled), shown in Figure \@ref(fig:MetaRob). Again, we can see a great deal of variation within both subgroups, and stratifying by risk of bias does not appear to have a noticeable effect on heterogeneity. High risk of bias studies appear to have the same amount of spread in results as do medium and low risk of bias studies.

```{r MetaRob}
knitr::include_graphics(here::here("figures", "rob-forest.png"))
```

In order to determine if there was an effect of publication year, we resorted the forest plot for the overall meta-analysis by publication year rather than by effect size in Figure \@ref(fig:MetaYr). Based solely on visual inspection of the forest plot, there seems to be no clear pattern in either effect size measurement or study precision over time, and so no further investigation of the potential effect of publication year was considered.

```{r MetaYr}
knitr::include_graphics(here::here("figures", "all-studies-forest-yr.png"))
```

Since the planned subgroup analyses provided no insight into heterogeneity in the synthesis results, several post-hoc outlier analyses were conducted. Using a basic method for outlier detection (as described previously), five studies were detected as outliers: Leon 2011, Teunis 2008, Bernstein 2015, Lindesmith 2005, and Atmar 2008. While removing these outliers has a large effect on the heterogeneity (updated $I^2 = 52\%$), we proceeded with other methods of outlier identification before making any further decisions.

Next, we performed a leave-one-out (LOO) influence analysis. The overall effect of removing each study is shown in Figure \@ref(fig:MetaLOOI2). Removing any one study appears to have little effect on the $I^2$, indicating that removing multiple studies is likely necessary to obtain a trustworthy summary estimate. From the LOO results, a Baujat plot was created, shown in Figure \@ref(fig:Baujat). Based on the Baujat plot and LOO diagnostics (shown in the appendix), we identified three studies as outliers: Bernstein 2015, Teunis 2008, and Madore 1990. Removing these three studies slightly decreases the heterogeneity (updated $I^2 = 73\%$).

```{r MetaLOOI2}
knitr::include_graphics(here::here("figures", "all-studies-loo-i2.png"))
```

```{r Baujat}
knitr::include_graphics(here::here("figures", "all-studies-loo-baujat.png"))
```

The final *post hoc* method for heterogeneity we considered was the GOSH method. The overall GOSH results are shown in Figure \@ref(fig:GOSH). There are a few remarkable patterns which can be observed in the GOSH plot. Notably, the majority of effect size estimates (log-odds, on the $x$-axis) fit a roughly normal distribution around a log-odds estimate of $0.5$ (corresponding to an estimated proportion infected of $0.62$), while the heterogeneity estimates of the random subset models have a skewed distribution. Most of the random subsets have a high $I^2$ estimate, around $80\%$. This indicates that attempting to deal with heterogeneity may be a fruitless pursuit, as the majority of the random subsets are quite heterogeneous. However, we can also see a number of random subset models with $I^2 = 0\%$, spread over a wide range of effect sizes. These subsets with $I^2 = 0\%$ are likely not meaningful or easy to find, however.

```{r GOSH}
knitr::include_graphics(here::here("figures", "all-studies-GOSH.png"))
```

We also used a *post hoc* clustering approach on the results of the GOSH analysis to identify outliers. Three clustering methods were applied, and the raw clustering results are shown in the appendix. The clustering methods identified four studies are potential outliers: Bernstein 2015, Leon 2011, Madore 1990, and Teunis 2008. Note that these detected outliers are the same as the LOO method, with the addition of the Leon study. Removing all four of these studies simultaneously lowers the $I^2$ estimate to $59\%$.

Using a consensus of the three outlier detection methods (a study is declared an outlier if any two of the three detection methods identified it), the studies we identify as outliers are: Bernstein 2015, Leon 2011, Madore 1990, and Teunis 2008. The forest plot with these four studies excluded is shown in Figure \@ref(fig:MetaNO). The $I^2$ with the outliers removed is $59\%$, and the 95% prediction interval remains quite wide. Notably, the consensus method failed to reduce heterogeneity any better than the simple method did, and the four studies identified as outliers have no superficial similarities which were not already examined (see Table \@ref(tab:StudyCharacteristics)). 

```{r MetaNO}
knitr::include_graphics(here::here("figures", "all-studies-NO.png"))
```

Table \@ref(tab:MetaSummary) shows summary statistics of the different methods we used to examine heterogeneity.

```{r MetaSummary}
sumdf <- data.frame(
  analysis = c("Overall", "Simple outliers", "Consensus outliers",
               "FUT2", "Genogroup", "Risk of bias"),
  prop = c("0.65", "0.72", "0.69", "0.69", "0.66", "0.65"),
  CI = c("(0.56, 0.74)", "(0.64, 0.78)", "(0.60, 0.76)", "(0.61, 0.76)",
         "(0.57, 0.75)", "(0.56, 0.74)"),
  PI = c("(0.27, 0.90)", "(0.45, 0.89)", "(0.38, 0.88)", "(0.37, 0.90)",
         "(0.28, 0.91)", "(0.27, 0.90)"),
  I2 = c("80% (70%, 87%)", "49% (09%, 71%)", "59% (39% - 77%)",
         "73% (58%, 83%)", "79% (68%, 86%)", "80% (70%, 87%)")
)
sumdf %>%
  flextable::flextable() %>%
  flextable::theme_booktabs(bold_header = TRUE) %>%
  flextable::align(j = 1, align = "right", part = "all") %>%
  flextable::align(j = 2:5, align = "center", part = "header") %>%
  flextable::align(j = 2:5, align = "left", part = "body") %>%
  flextable::set_caption("Summary estimates and heterogeneity for all synthesis analyses conducted.") %>%
  flextable::set_header_labels("I2" = "I^2") %>%
  flextable::footnote(
    i = 1, j = 2:5, part = "header",
    value = flextable::as_paragraph(
      c("Estimated proportion from random-effects model",
        "95% confidence interval for estimate",
        "95% prediction interval for estimate",
        "I^2 estimate with 95% confidence interval")
    )
  ) %>%
  flextable::fontsize(size = 10, part = "all") %>%
  flextable::autofit() %>%
  flextable::set_table_properties(layout = "autofit")
```

Finally, we assessed publication bias to determine if small-study effects or missing literature could explain the lack of coherent synthesis results. The results are shown visually in Figure \@ref(fig:Funnel). Some patterns are noticeable by visual inspection: notably, there is a cluster of 5 studies in the upper left with relatively high sample sizes which appear to estimate lower outcomes than the other studies. There also appear to be more studies which estimate high proportions than there are studies estimating low proportions as outcomes, even though many of these studies are not significant.

```{r Funnel, fig.cap = "Contour-enhanced funnel plot. Each point represents an included study. Contour shading indicates that the study result is significant at the shaded alpha level. The study in the bottom left is Atmar 2008, which estimated a proportion of 1."}
knitr::include_graphics(here::here("figures", "contour-funnel.png"))
```

We also assessed the asymmetry of the funnel plot using Peters' test (note that Peters' test for asymmetry is based on the slope of the regression line, rather than the intercept). The estimated slope was $\hat{\beta}_1 = 0.0328$ with an approximate 95% confidence interval of $(-4.97, 26.42)$. The test was not significant at a 95% level of confidence ($t_{18} = 1.34; \ p = 0.20$). The test is also shown visually in Figure \@ref(fig:PetersFig).

```{r PetersFig, fig.cap = "Visual representation of the Peters' test. The test fits a linear regression model with the estimated log-odds as the outcome and inverse sample size as the predictor, using inverse variance weighting, depicted as the size of the point. The regression line appears to have an intercept close to zero."}
knitr::include_graphics(here::here("figures", "peters-regression.png"))
```

From the test, we cannot conclude that there is definite evidence of asymmetry. However, visual inspection of the data does suggest interesting patterns which may be unrelated to problems that cause asymmetry.

# Discussion

# References

<div id="refs"></div>

# Other information {-}

The review has not been registered and no formal protocol was prepared before the review process began. The authors wish to declare that they have no competing interests.

All data sheets, along with cleaning and analysis code, are available on [GitHub](link), and the code at time of writing is archived on Zenodo: [doi url](link).

# R session information {-}

```{r session information}
pander::pander(sessionInfo())
```

# Study quality rubric {-}

1. (Clear Inclusion Criteria) Were there clear criteria for inclusion in the case series?
    + Yes: Inclusion criteria are stated clearly in the study.
    + No: Study was sampled by convenience or without clear exclusion criteria.
    + Unclear: Criteria for inclusion are not described.
2. (Reliable Condition Measure) Was the condition measured in a standard, reliable way for all participants included in the case series?
  + Yes: The same method was used to assess norovirus infection for all patients. 
  + No: Participants were assessed for infection in different ways.
  + Unclear: Method of assessing infection was not reported.
3. (Valid Condition Methods) Were valid methods used for identification of the condition for all participants included in the case series?
  + Yes: Infection was assessed using any molecular method (e.g. serology, PCR, etc.).
  + No: Infection was assessed using clinical symptoms alone.
  + Unclear: Method of assessing infection is not reported.
4. (Same Cohort) Were all participants sampled from the same underlying population at the same time? (I.e. did the participants form a single cohort?)
  + Yes: All participants were sampled from the same general population, or if multiple cohorts were pooled together during the study, the results are stratified by cohort. All patients were infected with the same inoculum, or stratified by inoculum.
  + No: Participants were recruited heterogeneously, or pooled cohort results were not stratified. Or patients with different inocula were pooled.
  + Unclear: Impossible to tell from given information whether participants were pooled from various cohorts without stratification or not.
5. (Complete Demographics) Was there clear reporting of the demographics of the participants included in the study?
  + Yes: Age range of participants was reported and medical history of patients was mentioned.
  + No: Age range is not reported or medical history not mentioned.
6. (Complete Clinical) Was there clear reporting of clinical information of the participants?
  + Yes: Infection outcome is reported for the same number of patients who were recruited. Or, if numbers are different, the loss of participants is explained.
  + No: Number of recruits reported does not match results, or number of total recruits is not reported.
7. (Site Information) Was there clear reporting of the presenting site or clinic demography?
  + Yes: authors describe the target population and state where the trial was conducted.
  + No: authors do not describe the study population or do not state where the trial was conducted.
  + Unclear: authors briefly describe the study site without detail, or describe the study site only as “multiple centers” or equivalent.
8. Overall risk of bias
  + Low: Yes in at least six domains, No in zero domains.
  + Moderate: Yes in at least five domains, No in at most one domain.
  + High: Yes in fewer than five domains, or No in more than one domain.